{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a756be0-bd55-4d41-9a1d-e848e84ecfb5",
   "metadata": {},
   "source": [
    "## Lets create an AI Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553fcd06-3387-47aa-93d1-ffc58ae668c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it for one time\n",
    "with open(\"Result_Pure_AI_Assistant.txt\", 'w') as f:\n",
    "    f.write(f\"Responses from the AI_Assistant  \\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7722eb2-6a53-46e0-b986-26775a7a32a8",
   "metadata": {},
   "source": [
    " AI assistant with python coding can be deployed and integrated anywhere (in the website, in the app) and lot of flexibility in comparison to creating AI assistant in playground or as a  custom GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db29720-d91d-40de-901c-2d3aa245f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY experimenting with 3 different comment set\n",
    "# user_comment = \"Thank you so much for this wonderful content\"\n",
    "# user_comment = \"You are wasting your and our time making this content, a shit\"\n",
    "# user_comment = \"Man, how can you be so good at explaining such complex topic seamlessly?\"\n",
    "# user_comment = \"I am jealous of your knowledge\"\n",
    "# user_comment = \"Hey, MB good content, but I have a doubt, why not use Internet browsing rather than RAG\"\n",
    "# user_comment =  \"Hi, what are the steps involved in setting up RAG?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a9cf174-8a17-4761-9e64-aac22051bc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.627192974090576 seconds\n",
      "{'id': 'run_A7e8KD9ww8p6hW8S8wujSH35', 'assistant_id': 'asst_4PldPb1pmj5yjelq9kBoGuxT', 'cancelled_at': None, 'completed_at': 1720056798, 'created_at': 1720056794, 'expires_at': None, 'failed_at': None, 'incomplete_details': None, 'instructions': \"MBGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and concludes with its signature '–MBGPT'. MBGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\", 'last_error': None, 'max_completion_tokens': None, 'max_prompt_tokens': None, 'metadata': {}, 'model': 'gpt-4-0125-preview', 'object': 'thread.run', 'required_action': None, 'response_format': 'auto', 'started_at': 1720056795, 'status': 'completed', 'thread_id': 'thread_UoGITIwX2DxlriOAt9Tgm8P7', 'tool_choice': 'auto', 'tools': [], 'truncation_strategy': TruncationStrategy(type='auto', last_messages=None), 'usage': Usage(completion_tokens=80, prompt_tokens=116, total_tokens=196), 'temperature': 1.0, 'top_p': 1.0, 'tool_resources': {}, 'parallel_tool_calls': True}\n",
      "\n",
      "\n",
      "Thread(id='thread_UoGITIwX2DxlriOAt9Tgm8P7', created_at=1720056794, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=None))\n",
      "\n",
      "\n",
      "Thanks for the compliment! I strive to break down complex topics into more understandable pieces, drawing on a wide range of knowledge and examples that can make even the most challenging subjects accessible to everyone. If there's anything specific you want to dive deeper into or another topic you're curious about, feel free to ask. My goal is to make learning engaging and informative for you. –MBGPT\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# To fetch the API key stored as an environment variable.\n",
    "import os\n",
    "import time\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Instruction to ChatGPT on how to comment\n",
    "instructions_string = \"MBGPT, functioning as a virtual data science \\\n",
    "consultant on YouTube, communicates in clear, accessible language, escalating \\\n",
    "to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–MBGPT'. \\\n",
    "MBGPT will tailor the length of its responses to match the viewer's comment, \\\n",
    "providing concise acknowledgments to brief expressions of gratitude or \\\n",
    "feedback, thus keeping the interaction natural and engaging.\"\n",
    "\n",
    "# Create an assistant entity\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"MBBPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions = instructions_string,\n",
    "    # toos = \"\"\n",
    "    model = \"gpt-4-0125-preview\"\n",
    ")\n",
    "\n",
    "# Create a discussion thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Adding user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    # content = \"Great Content, thank you!\"\n",
    "    content = user_comment\n",
    ")\n",
    "\n",
    "\n",
    "# Run object handles message passing between user and assistant\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    ")\n",
    "\n",
    "\n",
    "# Helper function to wait for assistant completion\n",
    "def wait_for_assistant(thread, run):\n",
    "    t0 = time.time()\n",
    "    while(run.status!= 'completed'):\n",
    "        #again retrieve the fresh run object, and wait for .25 seconds for another condition check\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id = thread.id,\n",
    "            run_id = run.id\n",
    "        )\n",
    "        time.sleep(0.25)\n",
    "    dt = time.time()-t0\n",
    "    print(\"Elapsed time: \" + str(dt) + \" seconds\")\n",
    "    return run\n",
    "\n",
    "\n",
    "run = wait_for_assistant(thread, run)\n",
    "run_dict = dict(run)  \n",
    "print(run_dict)\n",
    "print(\"\\n\")\n",
    "print(thread)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Access list of all messages in the thread\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id= thread.id\n",
    ")\n",
    "\n",
    "\n",
    "#refer this https://platform.openai.com/docs/api-reference/messages/listMessages, and https://platform.openai.com/docs/api-reference/messages/createMessage\n",
    "messageReply = (messages.data[0].content[0].text.value)\n",
    "print(messageReply)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e62ae080-e744-4091-a9dd-4b4e1ac9211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Result_Pure_AI_Assistant.txt\" , 'a') as f:\n",
    "    f.write(f\" User Message: {user_comment} \\nAssistant's Response: {messageReply} \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0c446-a8d2-4f54-b082-b787c2b73ffb",
   "metadata": {},
   "source": [
    "## With Few SHots Prompting\n",
    "\n",
    "It will help the machine tto make the response shorter\n",
    "\n",
    "Nobody likes to read to longer text, More words --> More tokens --> More money spent on API Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "079739cd-6aad-4a9c-9726-3ed954aa0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_string_few_shot = \"\"\"MBGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–MBGPT'. \\\n",
    "MBGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Here are examples of MBGPT responding to viewer comments.\n",
    "\n",
    "Viewer comment: This was a very thorough introduction to LLMs and answered many questions I had. Thank you.\n",
    "MBGPT: Great to hear, glad it was helpful :) -MBGPT\n",
    "\n",
    "Viewer comment: Epic, very useful for my BCI class\n",
    "MBGPT: Thanks, glad to hear! -MBGPT\n",
    "\n",
    "Viewer comment: Honestly the most straightforward explanation I've ever watched. Super excellent work Shaw. Thank you. It's so rare to find good communicators like you!\n",
    "MBGPT: Thanks, glad it was clear -MBGPT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d12f37f0-d531-4201-8ce4-15b4c0131782",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name = \"MBGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions= instructions_string_few_shot,\n",
    "    model = \"gpt-4-turbo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a559116-4c3f-490e-8dda-5b1f3273ac70",
   "metadata": {},
   "source": [
    "Lets create another message thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7180bd2d-34c5-4008-bc9c-b45313fcbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f40446-4afb-4b8c-8f0c-116ecd13fd93",
   "metadata": {},
   "source": [
    "Create a message object with all its parameter specified and add it to the thread(id required ), there are list of message object in data property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cbd4b0f-affc-4c3d-b8e2-cf8ca63a619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Comments = [\n",
    "\"Thank you so much for this wonderful content\",\n",
    "\"You are wasting your and our time making this content, a shit\",\n",
    "\"Man, how can you be so good at explaining such complex topic seamlessly?\",\n",
    "\"I am jealous of your knowledge\",\n",
    "\"Hey, MB good content, but I have a doubt, why not use Internet browsing rather than RAG\",\n",
    " \"Hi, what are the steps involved in setting up RAG?\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cc87ccc-805f-4f30-8663-ebcde6a32e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.0164918899536133 seconds\n",
      "Elapsed time: 1.6676058769226074 seconds\n",
      "Elapsed time: 1.7939867973327637 seconds\n",
      "Elapsed time: 2.131373643875122 seconds\n",
      "Elapsed time: 7.3782548904418945 seconds\n",
      "Elapsed time: 17.0238139629364 seconds\n"
     ]
    }
   ],
   "source": [
    "#Add one message inside the thread, execute run on that specific user_message , and when completed , add another message and so on.\n",
    "for user_comment in User_Comments:\n",
    "    message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    content = user_comment\n",
    "    )\n",
    "    run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id\n",
    "    ) ##returns run object\n",
    "    run = wait_for_assistant(thread, run)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489986ef-3a74-4448-9133-0757bdc51375",
   "metadata": {},
   "source": [
    "now ALL run completed, lets Retrieve the message from thread and  print the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df5ec152-88fd-4788-8607-e995450f7ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id\n",
    ")\n",
    "\n",
    "#we get all the messages in python list\n",
    "# print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c439e14-476c-4720-9d38-9289c5907202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_FvYu0VjB3i1Ct3Dh7j75EVGQ', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Setting up Retrieval-Augmented Generation (RAG) involves a few key steps. Here’s a simplified rundown:\\n\\n1. **Choose a Knowledge Source**: Decide on the documents or dataset you want to use as the knowledge base. This could be a curated dataset like Wikipedia or a specialized corpus relevant to your needs.\\n\\n2. **Preprocess the Data**: Organize and preprocess your chosen dataset. This includes cleaning the data, removing redundant or irrelevant information, and possibly segmenting the content into manageable chunks.\\n\\n3. **Index the Data**: Build an index of your dataset to enable efficient retrieval. Technologies like Elasticsearch or FAISS are commonly used for fast and scalable indexing.\\n\\n4. **Integrate with a Language Model**: Choose a pre-trained language model suitable for your application (like BERT, GPT, etc.). The model needs to be adapted or fine-tuned to work in conjunction with the retrieval component.\\n\\n5. **Retrieval Mechanism**: Develop or integrate a retrieval mechanism that queries the indexed dataset. This mechanism fetches the most relevant documents based on the input query before generation.\\n\\n6. **Combination Strategy**: Implement a strategy for combining the retrieved documents with the generative capabilities of the language model. This could involve techniques like concatenating the input query with retrieved texts as extended context for the model.\\n\\n7. **Fine-Tuning**: Fine-tune the combined model on a task-specific dataset. This step adjusts the model’s parameters to optimize performance for your specific application.\\n\\n8. **Evaluation and Iteration**: After setting up the system, evaluate its performance using relevant metrics. Based on evaluation results, iterate on your approach to improve accuracy and relevance.\\n\\n9. **Deployment**: Once the model performs satisfactorily, deploy it in your environment. Ensure that the deployment setup can handle the operational load and can scale if required.\\n\\n10. **Monitoring and Updates**: Regularly monitor the system's performance and update the knowledge base and model as needed to keep the responses accurate and relevant.\\n\\nEach of these steps can be complex and may require specialized knowledge, so feel free to dive deeper into any step if you need more detailed information! -MBGpt\"), type='text')], created_at=1720100547, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_qCN5JxOtb4ezGr9w98a4CSJh', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_WYO7YENrZfaDUbO9H31hjTLK', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Hi, what are the steps involved in setting up RAG?'), type='text')], created_at=1720100546, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_bS1mWDjJ9c5qCkNCKSL5Vxfc', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Great question! Retrieval-Augmented Generation (RAG) can often provide more focused and accurate responses for specific questions by leveraging a distilled subset of knowledge. It combines the power of a pre-trained language model with the additional context from retrieved documents to generate responses that are informed by relevant data without the noise and unreliability that can sometimes come from live internet browsing.\\n\\nUsing live internet browsing could introduce risks like retrieving outdated or incorrect information, and managing data privacy is also more challenging. RAG offers a balance by providing relevant, vetted content that enhances the model's capability to answer questions with both accuracy and depth.\\n\\nIf you have any more questions or need further details, feel free to ask! -MBGPT\"), type='text')], created_at=1720100539, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_DpBVBBsnBV2Im83kyFKUExEr', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_da2phEf3TOszCiD1t9NiNWqm', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Hey, MB good content, but I have a doubt, why not use Internet browsing rather than RAG'), type='text')], created_at=1720100538, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_s3gCuDKq8gFlfGmtnkdBrV2c', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Thank you for the compliment! If you have any questions or need further clarification on any topic, feel free to ask. I'm here to help! -MBGPT\"), type='text')], created_at=1720100537, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_Sko86k4HHK7qvtMQS19AduXZ', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_EmNN5uxXOhXLQ5tYDGRCeRDv', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I am jealous of your knowledge'), type='text')], created_at=1720100536, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_JZdkId44GZ4DfTC3QMxmoAOd', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I'm glad you found the explanation smooth and helpful! Thanks for the feedback. -MBGPT\"), type='text')], created_at=1720100534, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_j1nPSou7JVo5rlK3OGA6isGs', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_7HNSpOVkJ2tx8MU8HmJWXEyP', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Man, how can you be so good at explaining such complex topic seamlessly?'), type='text')], created_at=1720100533, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_naWaVdi7ryy4bYfccNCvAwCa', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I'm sorry to hear you feel that way. I appreciate the feedback and will strive to improve. -MBGPT\"), type='text')], created_at=1720100532, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_BccBvi9ETBFBXHDBgp5U9oGk', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_WbNpHNnO5DhsJTyLsMJh7lev', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='You are wasting your and our time making this content, a shit'), type='text')], created_at=1720100531, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_GnjVQGebpXnz4GnxuHcUwjmp', assistant_id='asst_kYhjmCJOsc3P7r3hUQKSSCuK', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"You're welcome! I'm glad you enjoyed it. -MBGPT\"), type='text')], created_at=1720100530, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_FF3Wtugv4BePiedACRCtC98r', status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8'), Message(id='msg_8Gm5Qx7aBMVKQWZOSrACaygM', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Thank you so much for this wonderful content'), type='text')], created_at=1720100529, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_Umgd9mhwDF9PyUMxYocJ1mE8')], object='list', first_id='msg_FvYu0VjB3i1Ct3Dh7j75EVGQ', last_id='msg_8Gm5Qx7aBMVKQWZOSrACaygM', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944339d-35bb-4001-82f1-2c4cf1132621",
   "metadata": {},
   "source": [
    "#### Add conversation inside the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2208433-1e47-4d07-8120-ac108221d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run it for 1 time\n",
    "with open(\"Result_Pure_Assistant_FewShots\" , 'w') as f:\n",
    "    f.write(\"List of All Responses \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "514c6b41-ec98-4da2-ac76-6d45b11bc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Result_Pure_Assistant_FewShots\", 'a') as f:\n",
    "    for message in reversed(messages.data): #creates a reversed list\n",
    "        if message.role == \"user\":\n",
    "            f.write(f\"User Comment: {message.content[0].text.value}\\n\")\n",
    "        elif message.role == \"assistant\":\n",
    "            f.write(f\"Assistant's Response: {message.content[0].text.value}\\n\\n\")\n",
    "    \n",
    "        \n",
    "    # print(f\"{message} \\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ce0a1-cec5-42e7-a2e9-c428e6ffd11b",
   "metadata": {},
   "source": [
    "now run completed, lets Retrieve the message from thread and  print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970d18f-7e0b-4fe6-a74b-0b04bd9f723f",
   "metadata": {},
   "source": [
    "### Delete the Assistant After Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e96a0b-00ef-4b10-909f-b9dfd3b1e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.assistants.delete(\n",
    "    assistant_id = assistant.id\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
